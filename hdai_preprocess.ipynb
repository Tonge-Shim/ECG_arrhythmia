{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b9ec760",
   "metadata": {},
   "source": [
    "### 아래 파일들은 제거!(했음)\n",
    "[arrhythmia]\n",
    "\n",
    "- train set\n",
    "    - 6으로 시작하는 파일: 1267, 1970, 3131, 3198, 3469, 3618, 4827, 4971, 4979, 5055\n",
    "    \n",
    "    - 8로 시작하는 파일: 1879, 2164, 5580, 총 13개 제거(직접 터미널에서 다 한 상태)\n",
    "    \n",
    "- validation set\n",
    "    - 여긴 다 8로 시작하는 파일: 7226, 7281, 8783(근데 여긴 허수가 좀 더 있을수도! 앞에 두개는 아예 생성이 안되고(생성이 안되는 경우, 확실히 2개는 맞음), 8783의 경우는 리드가 부족한 파일), 3개 제거\n",
    "    \n",
    "    이 외에도 약 37개(전부 data/train/arrhythmia에서만) 12개의 리드 중 몇 개의 리드의 길이가 짧은 데이터들은 무시하고 학습. \n",
    "    \n",
    "    \n",
    "[normal]의 경우, 오류 안나는 것 같음.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c83d8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import tqdm\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31318cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_arr = './data/train/arrhythmia/'\n",
    "train_path_nor = './data/train/normal/'\n",
    "val_path_arr = './data/validation/arrhythmia/'\n",
    "val_path_nor = './data/validation/normal/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2314aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr_list = os.listdir(train_path_arr)\n",
    "train_nor_list = os.listdir(train_path_nor)\n",
    "val_arr_list = os.listdir(val_path_arr)\n",
    "val_nor_list = os.listdir(val_path_nor)\n",
    "train_arr_list.sort()\n",
    "train_nor_list.sort()\n",
    "val_arr_list.sort()\n",
    "val_nor_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee1088e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17836, 21037, 2229, 2630)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_arr_list), len(train_nor_list), len(val_arr_list), len(val_nor_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff466d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20065, 23667)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_arr_list) +  len(val_arr_list), len(train_nor_list)+len(val_nor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ce98b63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ECGXMLReader import ECGXMLReader\n",
    "\n",
    "def decodefile(filepath, namelist):\n",
    "    file = []\n",
    "    for name in namelist:\n",
    "        file.append(ECGXMLReader(filepath + name, name, augmentLeads = True))\n",
    "    return file\n",
    "\n",
    "\n",
    "train_arr = decodefile(train_path_arr, train_arr_list)\n",
    "train_nor = decodefile(train_path_nor, train_nor_list)#나중에 train끼리 합체\n",
    "val_arr = decodefile(val_path_arr, val_arr_list)\n",
    "val_nor = decodefile(val_path_nor, val_nor_list)#val 끼리 합체\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8f6eef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [train_arr, train_nor, val_arr, val_nor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2562bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weirdos(decoded_data):#inputs: train_arr, train_nor, val_arr, val_nor/길이가 이상한 리스트 뽑기\n",
    "    diff_list = []\n",
    "    for i, file in enumerate(decoded_data):\n",
    "        l = []\n",
    "        arr = sorted(file.getAllVoltages().items())\n",
    "        for line in arr:\n",
    "            l.append(line[1])\n",
    "        l = np.asarray(l)\n",
    "        if l.shape != (12,5000) and l.shape != (12, 4999):#크기가 (12, 5000), (12, 4999)가 아닌 데이터들의 인덱스 리스트를 추출\n",
    "            diff_list.append(i)\n",
    "    print(\"length: \", len(diff_list))\n",
    "    return diff_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "fd4c4a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaeeun/.conda/envs/sce/lib/python3.7/site-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  37\n",
      "length:  0\n",
      "length:  0\n",
      "length:  0\n",
      "[[3390, 3893, 4418, 4465, 4487, 4608, 4746, 5134, 5314, 5345, 5452, 5819, 5840, 5873, 6368, 6425, 6471, 6884, 6943, 7280, 7466, 7524, 7643, 7816, 8128, 8242, 8458, 9204, 9262, 9328, 9462, 9556, 9596, 9761, 10499, 10786, 13109], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "diff_set=[]\n",
    "for x in namelist:\n",
    "    diff_set.append(find_weirdos(x))\n",
    "print(diff_set)\n",
    "#이 결과로 미루어 보아, train dataset에서만 이상한 길이들이 존재함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "1bfea2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_arr(data_list, diff_list):#train_arr, train_nor, val_arr, val_nor넣고 돌리기.4096길이로 자르기.\n",
    "    train_array = []\n",
    "    for i, file in enumerate(data_list):\n",
    "        if i in diff_list:# 앞에서 추출한 크기가 상이한 데이터들을 제외하고 array를 생성했습니다. \n",
    "            continue\n",
    "        l = []\n",
    "        arr = sorted(file.getAllVoltages().items())\n",
    "        for line in arr:\n",
    "            l.append(line[1])#나중에 여기서 변수를 받아서 선택적으로 리드를 뽑게 수정가능\n",
    "        l = np.asarray(l, dtype = object).astype('float32')\n",
    "        l = l[:, :4096]#나중에 얘도 변수화 하면 편하겠다, .T도 고려!transpose = True이런 식으로 argument\n",
    "        train_array.append(l)\n",
    "    return train_array#list로 return\n",
    "#향후 계획: list끼리 + --> 최종 trainset data 만들기. 향후 파이토치 모델에 넣을 시 shuffle의 작업이 꼭 필요함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be297bf5",
   "metadata": {},
   "source": [
    "### making array, save as a file .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "737b6443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38836, 12, 4096)\n",
      "(4859, 12, 4096)\n"
     ]
    }
   ],
   "source": [
    "train_arr_arraylist = making_arr(name_list[0], diff_set[0])\n",
    "train_nor_arraylist = making_arr(name_list[1], diff_set[1])\n",
    "val_arr_arraylist = making_arr(name_list[2], diff_set[2])\n",
    "val_nor_arraylist = making_arr(name_list[3], diff_set[3])\n",
    "\n",
    "train_array = np.asarray(train_arr_arraylist + train_nor_arraylist)\n",
    "val_array = np.asarray(val_arr_arraylist + val_nor_arraylist)\n",
    "s\n",
    "print(train_array.shape)\n",
    "print(val_array.shape)\n",
    "\n",
    "np.save('./data_np/train', train_array, allow_pickle=True, fix_imports=True)\n",
    "np.save('./data_np/validation', val_array, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4e0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63bfc3b5",
   "metadata": {},
   "source": [
    "### label 0, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e63551",
   "metadata": {},
   "source": [
    "label의 경우, json파일에서 추출후 변형하는 방법도 있겠지만, 주신 데이터가 아예 정상, 비정상이 따로 왔기 때문에 그냥 0, 1로 데이터 개수에 맞춰 리스트를 만든 후, 합쳐서 배열을 만들었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "8edd4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr_label = [1]*(17836-37)\n",
    "train_nor_label = [0]*21037\n",
    "val_arr_label = [1] * 2229\n",
    "val_nor_label = [0] * 2630\n",
    "train_label = np.asarray(train_arr_label + train_nor_label).astype('float32').reshape(-1,1)\n",
    "val_label = np.asarray(val_arr_label + val_nor_label).astype('float32').reshape(-1,1)\n",
    "np.save('./label_np/train', train_label, allow_pickle = True, fix_imports = True)\n",
    "np.save('./label_np/validation', val_label, allow_pickle = True, fix_imports = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8e92bdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38836, 1), (4859, 1))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape, val_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5dbf0",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "cbf3c7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38836, 1)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.reshape(-1,1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('sce': conda)",
   "language": "python",
   "name": "python3711jvsc74a57bd09bb3e46167f5c400af3e59bea929666d662dd7e99f9046bb04b64be6ff24130e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
